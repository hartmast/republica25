59-7
library(languageR)
languageR::lexdec
?languageR::lexdec
data("lexdec")
lexdec$Subject
810 + (0.19*810)
library(rstan)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library(rstan)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library(cmdstanr)
?install_cmdstan
rm("cmdstanr")
check_cmdstan_toolchain()
fit_temperature <- brm(
# specify what to explain in terms of what
#  using the formula syntax
formula = avg_temp ~ year,
# which data to use
data = aida::data_WorldTemp
)
library(brms)
install.packages("brms")
library(brms)
fit_temperature <- brm(
# specify what to explain in terms of what
#  using the formula syntax
formula = avg_temp ~ year,
# which data to use
data = aida::data_WorldTemp
)
install.packages("aida")
remotes::install_github("michael-franke/aida-package")
# remotes::install_github("michael-franke/aida-package")
fit_temperature <- brm(
# specify what to explain in terms of what
#  using the formula syntax
formula = avg_temp ~ year,
# which data to use
data = aida::data_WorldTemp
)
5000*9.16
5000*0.16
seq(94,160,length.out=11)
8415.21*3
5000/12
5000/15
333-109
416-109
library(afex)
allFit()
?allFit
citation("afex")
citation("afex")
?citation
bibentry("afex")
bibentry(citation("afex"))
print(citation("afex"), bibtex = TRUE)
citation()
citation("tidyverse")
library(wordcloud)
x <- c("Anglistik und Amerikanistik","Germanistik","Geschichte","Jüdische Studien","Kunstgeschichte","Modernes Japan","Philosophie","Romanistik","Anglistik und Amerikanistik","Germanistik","Geschichte","Jiddische Kultur, Sprache und Literatur","Jüdische Studien","Kommunikations- und Medienwissenschaft","Kunstgeschichte","Linguistik","Modernes Japan","Musikwissenschaft","Philosophie","Politikwissenschaft","Romanistik","Soziologie","Computerlinguistik","Linguistik","Medien- und Kulturwissenschaft","PPE - Philosophy, Politics and Economics","Sozialwissenschaften - Medien, Politik, Gesellschaft","Transkulturalität - Medien, Sprachen, Texte in einer globalisierten Welt",)
library(wordcloud)
x <- c("Anglistik und Amerikanistik","Germanistik","Geschichte","Jüdische Studien","Kunstgeschichte","Modernes Japan","Philosophie","Romanistik","Anglistik und Amerikanistik","Germanistik","Geschichte","Jiddische Kultur, Sprache und Literatur","Jüdische Studien","Kommunikations- und Medienwissenschaft","Kunstgeschichte","Linguistik","Modernes Japan","Musikwissenschaft","Philosophie","Politikwissenschaft","Romanistik","Soziologie","Computerlinguistik","Linguistik","Medien- und Kulturwissenschaft","PPE - Philosophy, Politics and Economics","Sozialwissenschaften - Medien, Politik, Gesellschaft","Transkulturalität - Medien, Sprachen, Texte in einer globalisierten Welt",))
x <- c("Anglistik und Amerikanistik","Germanistik","Geschichte","Jüdische Studien","Kunstgeschichte","Modernes Japan","Philosophie","Romanistik","Anglistik und Amerikanistik","Germanistik","Geschichte","Jiddische Kultur, Sprache und Literatur","Jüdische Studien","Kommunikations- und Medienwissenschaft","Kunstgeschichte","Linguistik","Modernes Japan","Musikwissenschaft","Philosophie","Politikwissenschaft","Romanistik","Soziologie","Computerlinguistik","Linguistik","Medien- und Kulturwissenschaft","PPE - Philosophy, Politics and Economics","Sozialwissenschaften - Medien, Politik, Gesellschaft","Transkulturalität - Medien, Sprachen, Texte in einer globalisierten Welt")
set.seed(92368)
wordcloud(x)
x <- "Anglistik und Amerikanistik","Germanistik","Geschichte","Jüdische Studien","Kunstgeschichte","Modernes Japan","Philosophie","Romanistik","Anglistik und Amerikanistik","Germanistik","Geschichte","Jiddische Kultur, Sprache und Literatur","Jüdische Studien","Kommunikations- und Medienwissenschaft","Kunstgeschichte","Linguistik","Modernes Japan","Musikwissenschaft","Philosophie","Politikwissenschaft","Romanistik","Soziologie","Computerlinguistik","Linguistik","Medien- und Kulturwissenschaft","PPE - Philosophy, Politics and Economics","Sozialwissenschaften - Medien, Politik, Gesellschaft","Transkulturalität - Medien, Sprachen, Texte in einer globalisierten Welt")
?wordcloud
wordcloud(words = x, freqs = rep(1, length(x)))
tibble(x = words)
tibble(words = x)
library(tidyverse)
x <- tibble(words = x)
x
x$freqs <- 1
x
wordclud(words = x$words, freqs)
wordcloud(words = x$words, freq = x$freqs)
wordcloud(words = x$words, freq = x$freqs, colors = terrain.colors())
wordcloud(words = x$words, freq = x$freqs, colors = terrain.colors(n = nrow(x)))
use.warnings()
warnings()
nchar(x$words)
x$nchar <- nchar(x$words)
wordcloud(words = x$words, freq = x$nchar, colors = terrain.colors(n = nrow(x)))
x <- c("Anglistik und Amerikanistik","Germanistik","Geschichte","Jüdische Studien",
"Kunstgeschichte","Modernes Japan","Philosophie","Romanistik","Anglistik und Amerikanistik",
"Germanistik","Geschichte","Jiddische Kultur, Sprache und Literatur","Jüdische Studien",
"Kommunikations- und Medienwissenschaft","Kunstgeschichte","Linguistik","Modernes Japan",
"Musikwissenschaft","Philosophie","Politikwissenschaft","Romanistik","Soziologie","Computerlinguistik",
"Linguistik","Medien- und Kulturwissenschaft","PPE - Philosophy, Politics and Economics","Sozialwissenschaften",
"Transkulturalität")
set.seed(92368)
x <- tibble(words = x)
x$nchar <- nchar(x$words)
x$freqs <- 1
wordcloud(words = x$words, freq = x$nchar, colors = terrain.colors(n = nrow(x)))
x <- unique(x)
wordcloud(words = x$words, freq = x$nchar, colors = terrain.colors(n = nrow(x)))
set.seed(92368)
wordcloud(words = x$words, freq = x$nchar, colors = terrain.colors(n = nrow(x)))
set.seed(92368)
wordcloud(words = x$words, freq = round(log1p(x$nchar)), colors = terrain.colors(n = nrow(x)))
set.seed(92368)
wordcloud(words = x$words, freq = x$nchar, colors = terrain.colors(n = nrow(x)))
set.seed(923788)
wordcloud(words = x$words, freq = x$nchar, colors = terrain.colors(n = nrow(x)))
x
set.seed(923788)
wordcloud(words = x$words, freq = x$nchar/2, colors = terrain.colors(n = nrow(x)))
wordcloud(words = x$words, freq = x$nchar/5, colors = terrain.colors(n = nrow(x)))
library(ggwordcloud)
x %>% ggplot(aes(label = words, size = freqs)) +
geom_text_wordcloud()
x %>% ggplot(aes(label = words, size = freqs, color = nchar)) +
geom_text_wordcloud()
x %>% ggplot(aes(label = words, size = freqs, color = nchar)) +
geom_text_wordcloud() +
scale_color_viridis_b()
x %>% ggplot(aes(label = words, size = freqs, color = nchar)) +
geom_text_wordcloud_area() +
scale_color_viridis_b()
x %>% ggplot(aes(label = words, size = freqs, color = nchar)) +
geom_text_wordcloud_area() +
scale_color_viridis_b()
set.seed(42)
ggwordcloud2(love_words_small[, c("word", "speakers")], size = 2.5)
love_words_small
ggwordcloud2([x[, c("words", "freqs")]])
ggwordcloud2(x[, c("words", "freqs")])
set.seed(2)
set.seed(5)
x$freqs <- sample(1:3, nrow(x), replace = T)
set.seed(2)
ggwordcloud2(x[, c("words", "freqs")])
x$freqs <- sample(seq(0.1,3.9, .1), nrow(x), replace = T)
set.seed(5)
x$freqs <- sample(seq(0.1,3.9, .1), nrow(x), replace = T)
x <- unique(x)
set.seed(923789)
wordcloud(words = x$words, freq = x$nchar/5, colors = terrain.colors(n = nrow(x)))
set.seed(2)
ggwordcloud2(x[, c("words", "freqs")])
x
set.seed(5)
x$freqs <- sample(seq(0.1,2.1, .1), nrow(x), replace = T)
x <- unique(x)
set.seed(923789)
wordcloud(words = x$words, freq = x$nchar/5, colors = terrain.colors(n = nrow(x)))
set.seed(2)
ggwordcloud2(x[, c("words", "freqs")])
set.seed(2)
ggwordcloud2(x[, c("words", "freqs")], size = 2.5)
ggwordcloud2(x[, c("words", "freqs")], size = 1)
ggwordcloud2(x[, c("words", "freqs")], size = .5)
ggwordcloud2(x[, c("words", "freqs")], size = .7)
set.seed(1999)
ggwordcloud2(x[, c("words", "freqs")], size = .7)
x <- c("Anglistik und Amerikanistik","Germanistik","Geschichte","Jüdische Studien","Kunstgeschichte","Modernes Japan","Philosophie","Romanistik","Computerlinguistik","Linguistik","Medien- und Kulturwissenschaft","Philosophy, Politics and Economics","Sozialwissenschaften","Transkulturalität")
x <- tibble(words = x)
x$nchar <- nchar(x$words)
set.seed(5)
x$freqs <- sample(seq(0.1,2.1, .1), nrow(x), replace = T)
x <- unique(x)
set.seed(923789)
wordcloud(words = x$words, freq = x$nchar/5, colors = terrain.colors(n = nrow(x)))
set.seed(1999)
ggwordcloud2(x[, c("words", "freqs")], size = .7)
ggwordcloud2(x[, c("words", "freqs")], size = .9)
set.seed(7)
x$freqs <- sample(seq(0.1,2.1, .1), nrow(x), replace = T)
x <- unique(x)
set.seed(923789)
wordcloud(words = x$words, freq = x$nchar/5, colors = terrain.colors(n = nrow(x)))
set.seed(1999)
ggwordcloud2(x[, c("words", "freqs")], size = .9)
x$freqs <- 1
ggwordcloud2(x[, c("words", "freqs")], size = .9)
ggwordcloud2(x[, c("words", "freqs")], size = .1)
x$freqs <- 1
ggwordcloud2(x[, c("words", "freqs")], size = .1)
x$freqs <- 1
ggwordcloud2(x[, c("words", "freqs")], size = .5)
set.seed(1985)
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar)) +
geom_text_wordcloud_area() +
scale_color_viridis_b()
set.seed(1985)
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area() +
scale_color_viridis_b()
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area() +
scale_color_viridis_b() +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18))
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area(size = 2) +
scale_color_viridis_b()
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area(size = 12) +
scale_color_viridis_b()
set.seed(1985)
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area(size = 20) +
scale_color_viridis_b()
set.seed(1985)
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area(size = 20) +
scale_color_viridis_b(begin = .1, end = .9)
x %>%
mutate(angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))) %>%
ggplot(aes(label = words, size = freqs, color = nchar, angle = angle)) +
geom_text_wordcloud_area(size = 20) +
scale_color_viridis_b(begin = .1, end = .8)
ggsave("wc.png", bg = "transparent")
5000-1479
3521/14
5000-1576
3424/14
3424/15
paste0(sample(c(0:9, LETTERS, letters, "!", "?")), 10)
paste0(sample(c(0:9, LETTERS, letters, "!", "?"), 10))
paste0(sample(c(0:9, LETTERS, letters, "!", "?"), 10), collapse = "")
paste0(sample(c(0:9, LETTERS, letters, "!", "?"), 10), collapse = "")
paste0(sample(c(0:9, LETTERS, letters, "!", "?"), 10), "!" collapse = "")
paste0(sample(c(0:9, LETTERS, letters, "!", "?"), 10), "!", collapse = "")
1470.04*0.81
1050.67*0.81
1680.01*0.81
1515.72*0.81
109*0.81
1000/88.29
setwd("~/sciebo/Seminare/Seminare SoSe 2025/RePopulismus/Programm")
library(tidyverse)
paste0("https://re-publica.com/en/sessions?page=", 0)
paste0("https://re-publica.com/en/sessions?page=", 0:14)
f <- paste0("https://re-publica.com/en/sessions?page=", 0:14)
d <- readLines(f[1])
d
# Abschnitte finden
sec <- grep("role=\"article\"", d)
# in Abschnitten Titel und Beschreibung finden
d[sec[1]:sec[1+1]]
# in Abschnitten Titel und Beschreibung finden
cur <- d[sec[1]:sec[1+1]]
grep("<span>", cur)[1]
cur[grep("<span>", cur)[1]]
gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
grep("Summary</div>", cur)
grep("Summary</div>", cur)+1
cur[grep("Summary</div>", cur)+1]
gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1])
gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
smry <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
ttl <- gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
cur
grep("speaker", cur)
cur[grep("speaker", cur)[1]]
gsub("<.*?>", "", cur[grep("speaker", cur)[1]])
gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
speaker <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
cur
grep("a href", cur)
grep("a href", cur)[1]
gsub("<.*?>", "", grep("a href", cur)[1])
gsub("<.*?>", "", cur[grep("a href", cur)[1]])
cur[grep("a href", cur)[1]]
gsub(".*href=\"", "", cur[grep("a href", cur)[1]])
gsub("\\".*", " ,gsub(".*href=\"", "", cur[grep("a href", cur)[1]]))
gsub("\".*", "-,gsub(".*href=\"", "", cur[grep("a href", cur)[1]]))
gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]]))
paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
link <- paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
for(i in 1:(length(sec)-1)) {
cur <- d[sec[1]:sec[1+1]]
ttl <- gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
smry <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
speaker <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
link <- paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
cur_tbl <- tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
if(i == 1) {
all_tbl = cur_tbl
} else {
all_tbl = rbind(all_tbl, cur_tbl)
}
}
all_tbl
for(i in 1:(length(sec)-1)) {
cur <- d[sec[i]:sec[i+1]]
ttl <- gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
smry <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
speaker <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
link <- paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
cur_tbl <- tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
if(i == 1) {
all_tbl = cur_tbl
} else {
all_tbl = rbind(all_tbl, cur_tbl)
}
}
all_tbl
length(f)
for(j in 1:length(f)) {
d <- readLines(f[j])
# Abschnitte finden
sec <- grep("role=\"article\"", d)
# in Abschnitten Titel und Beschreibung finden
for(i in 1:(length(sec)-1)) {
cur <- d[sec[i]:sec[i+1]]
ttl <- gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
smry <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
speaker <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
link <- paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
cur_tbl <- tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
if(i == 1 & j == 1) {
all_tbl = cur_tbl
} else {
all_tbl = rbind(all_tbl, cur_tbl)
}
}
print(i)
}
all_tbl
# export
write_rds(all_tbl, "all_tbl.Rds")
rm(list=ls())
library(tidyverse)
library(DT)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: libs
library(tidyverse)
library(DT)
d <- read_rds("all_tbl.Rds")
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20
))
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20
),   autoWidth = TRUE,
columnDefs = list(list(width = '200px', targets = c(1, 3))))
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(list(width = '200px', targets = c(1, 3)))
))
?datatable
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(list(width = '40%', targets = c(2)))
))
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(list(width = '70%', targets = c(2)))
))
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(list(width = '70%', targets = c(3)))
))
paste0("<a href=", d$title, ">")
paste0("<a href=", d$title, "></a>")
paste0("<a href=", d$link, "></a>")
paste0("<a href=\"", d$link, "\"></a>")
paste0("<a href=\"", d$link, "\">Link</a>")
d$link <- paste0("<a href=\"", d$link, "\">Link</a>")
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(list(width = '70%', targets = c(3)))
))
gsub("//de", "/de", d$link)
d$link <- gsub("//de", "/de", d$link)
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(
list(width = '70%', targets = c(3)),  # Keep the 4th column width as before
list(width = '150px', targets = c(1))  # Set the width of the 1st column to 150px
)
), escape = FALSE)
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(
list(width = '200px', targets = c(2)),  # Keep the 4th column width as before
list(width = '150px', targets = c(1))  # Set the width of the 1st column to 150px
)
), escape = FALSE)
datatable(d,
options = list(
search = list(regex = TRUE, caseInsensitive = TRUE),
pageLength = 20,
autoWidth = TRUE,
columnDefs = list(
list(width = '500px', targets = c(2)),  # Keep the 4th column width as before
list(width = '150px', targets = c(1))  # Set the width of the 1st column to 150px
)
), escape = FALSE)
library(tidyverse)
f <- paste0("https://re-publica.com/en/sessions?page=", 0:25)
for(j in 1:length(f)) {
d <- readLines(f[j])
# Abschnitte finden
sec <- grep("role=\"article\"", d)
# in Abschnitten Titel und Beschreibung finden
for(i in 1:(length(sec)-1)) {
cur <- d[sec[i]:sec[i+1]]
ttl <- gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
smry <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
speaker <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
link <- paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
cur_tbl <- tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
if(i == 1 & j == 1) {
all_tbl = cur_tbl
} else {
all_tbl = rbind(all_tbl, cur_tbl)
}
}
print(i)
}
all_tbl
# export
write_rds(all_tbl, "all_tbl.Rds")
library(tidyverse)
f <- paste0("https://re-publica.com/en/sessions?page=", 0:28)
for(j in 1:length(f)) {
d <- readLines(f[j])
# Abschnitte finden
sec <- grep("role=\"article\"", d)
# in Abschnitten Titel und Beschreibung finden
for(i in 1:(length(sec)-1)) {
cur <- d[sec[i]:sec[i+1]]
ttl <- gsub("<.*?>", "", cur[grep("<span>", cur)[1]])
smry <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("Summary</div>", cur)+1]))
speaker <- gsub("^ +", "", gsub("<.*?>", "", cur[grep("speaker", cur)[1]]))
link <- paste0("https://re-publica.com/", gsub("\".*", "", gsub(".*href=\"", "", cur[grep("a href", cur)[1]])))
cur_tbl <- tibble(title = ttl,
summary = smry,
speaker = speaker,
link = link)
if(i == 1 & j == 1) {
all_tbl = cur_tbl
} else {
all_tbl = rbind(all_tbl, cur_tbl)
}
}
print(i)
}
# export
write_rds(all_tbl, "all_tbl.Rds")
